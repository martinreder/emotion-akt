{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import tensorflow as tf\n",
    "from load_fer2013 import load_fer2013, preprocess\n",
    "\n",
    "def load_and_preprocess_data() -> Tuple[tf.data.Dataset, tf.data.Dataset, tf.data.Dataset]:\n",
    "    data = load_fer2013()\n",
    "    num_classes = 7\n",
    "\n",
    "    # Define splits for train, validation, and test sets\n",
    "    split_train = int(len(data) * 0.7)\n",
    "    split_test = int(len(data) * 0.1)\n",
    "    split_val = len(data) - split_train - split_test\n",
    "\n",
    "    # Create a TensorFlow dataset from the data\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(data))\n",
    "    dataset = dataset.map(\n",
    "        lambda row: preprocess(row, num_classes), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Partition the data into train, validation, and test sets\n",
    "    train_dataset = (\n",
    "        dataset.take(split_train).shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    val_dataset = (\n",
    "        dataset.skip(split_train).take(split_val).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    test_dataset = (\n",
    "        dataset.skip(split_train + split_val).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "113/113 [==============================] - 3s 13ms/step - loss: 1.2757 - accuracy: 0.5256 - categorical_accuracy: 0.5256\n",
      "Testing accuracy: [1.275729775428772, 0.5256410241127014, 0.5256410241127014]\n",
      "113/113 [==============================] - 3s 13ms/step\n",
      "First prediction [0.32203916 0.01416158 0.04879333 0.24709927 0.19526306 0.02899002\n",
      " 0.14365356]\n",
      "Predicted class for the first test example: 0 = Happy\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model from the specified path\n",
    "model_path = 'output/best_model'\n",
    "model = load_model(model_path)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = load_and_preprocess_data()\n",
    "\n",
    "# metrics from model.evaluate\n",
    "val_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Testing accuracy: {val_accuracy}\")\n",
    "\n",
    "# Get predictions for test data\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Since 'predictions' is a 2D array, each row corresponds to predictions for a given input\n",
    "# To get the first prediction, we select the first row\n",
    "first_prediction = predictions[0]\n",
    "\n",
    "# Get the class with the highest probability from the first prediction\n",
    "predicted_class = np.argmax(first_prediction)\n",
    "print(f\"First prediction {first_prediction}\")\n",
    "print(f\"Predicted class for the first test example: {predicted_class} = Happy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
